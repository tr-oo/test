import json #–°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
import re
import logging
import os
from uuid import uuid4

import requests

from dotenv import load_dotenv # –°—Ç–æ—Ä–æ–Ω–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
from gigachat import GigaChat
from langchain_text_splitters import RecursiveCharacterTextSplitter
from qdrant_client import QdrantClient
from qdrant_client.models import Distance, PointStruct, VectorParams
from sentence_transformers import SentenceTransformer
from transformers import logging as transformers_logging

load_dotenv()
GIGA_KEY=os.getenv('GIGACHAT_API_KEY')
HF_API_KEY=os.getenv("HF_API_KEY")
QDRANT_KEY=os.getenv("QDRANT_KEY")

# –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º –æ–±—â–∏–π —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(
    level=logging.ERROR,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    )
# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Ñ–∞–π–ª–æ–≤–æ–≥–æ —Ö—ç–Ω–¥–ª–µ—Ä–∞ –¥–ª—è –æ—à–∏–±–æ–∫
error_log_file = 'errors.log'
file_handler = logging.FileHandler(error_log_file) 
file_handler.setLevel(logging.ERROR) # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —É—Ä–æ–≤–µ–Ω—å (—Ç–æ–ª—å–∫–æ –æ—à–∏–±–∫–∏)

formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')
file_handler.setFormatter(formatter)

# –î–æ–±–∞–≤–ª—è–µ–º —Ñ–∞–π–ª–æ–≤—ã–π —Ö—ç–Ω–¥–ª–µ—Ä –∫ –∫–æ—Ä–Ω–µ–≤–æ–º—É –ª–æ–≥–≥–µ—Ä—É
root_logger = logging.getLogger()
root_logger.addHandler(file_handler)

# –õ–æ–≥–≥–µ—Ä –¥–ª—è GigaChat. –£—Ä–æ–≤–µ–Ω—å INFO –ø–æ–∑–≤–æ–ª–∏—Ç –≤–∏–¥–µ—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π –∏ –æ—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –ª–æ–≥–∞—Ö.
giga_logger = logging.getLogger("GigaChatProcessor")
giga_logger.setLevel(logging.INFO)

# –°–æ–∑–¥–∞–µ–º –ª–æ–≥–≥–µ—Ä –¥–ª—è –æ–±—â–∏—Ö –æ—à–∏–±–æ–∫ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –¥–∞–Ω–Ω—ã—Ö
data_processor_logger = logging.getLogger("DataProcessor") 
data_processor_logger.setLevel(logging.INFO) 

# –õ–æ–≥–≥–µ—Ä –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π –æ—á–∏—Å—Ç–∫–∏ —Ç–µ–∫—Å—Ç–∞
simple_clean_logger = logging.getLogger("SimpleTextCleaner")
simple_clean_logger.setLevel(logging.INFO)

# –û—Ç–∫–ª—é—á–∞–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è transformers
transformers_logging.set_verbosity_error()

# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ GigaChat
try: 
    giga_client = GigaChat(
        credentials=GIGA_KEY, 
        verify_ssl_certs=False, 
        # scope='YOUR_SCOPE',
        # ca_bundle_file="russian_trusted_root_ca.cer"
    )
    logging.info("GigaChat –∫–ª–∏–µ–Ω—Ç —É—Å–ø–µ—à–Ω–æ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω.")
except Exception as e:
    logging.critical(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: –ù–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å GigaChat –∫–ª–∏–µ–Ω—Ç: {e}. –ü—Ä–æ–≥—Ä–∞–º–º–∞ –∑–∞–≤–µ—Ä—à–∞–µ—Ç —Ä–∞–±–æ—Ç—É.")
    exit(1)

#–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ qdrant
qdrant_client = QdrantClient(
    url="https://3c72576e-1fc3-4fa5-8a64-faee22471802.europe-west3-0.gcp.cloud.qdrant.io", 
    api_key=QDRANT_KEY,
)

#–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ 
embedding_model = SentenceTransformer("ai-forever/ru-en-RoSBERTa")

# –ü—Ä–æ—Å—Ç–æ–π –≤—ã–∑–æ–≤ GigaChat
def my_giga():
    giga = GigaChat(
    credentials=GIGA_KEY,
    verify_ssl_certs=False,
    )

    user_prompt="–ö–∞–∫–æ–π —Å–µ–π—á–∞—Å –ø—Ä–µ–∑–∏–¥–µ–Ω—Ç –°–®–ê?"

    messages_payload = {"messages": [{"role": "user", "content": user_prompt}]} #messages_payload = [{"role": "user", "content": user_prompt}] list –∞ –±–∏–±–ª–∏–æ—Ç–µ–∫–∞ gigachat –∂–∏–¥–∞–µ—Ç –ø–æ–ª—É—á–∏—Ç—å –æ–±—ä–µ–∫—Ç —Å –∫–ª—é—á–æ–º "messages" 
    response=giga.chat(messages_payload)
    print(response.choices[0].message.content)

# –í—ã–∑–æ–≤ GigaChat —Å –ø—Ä–æ–º—Ç–æ–º
def context_ask():
    giga = GigaChat(
    credentials=os.getenv('GIGACHAT_API_KEY'),
    verify_ssl_certs=False,
    )
    user_prompt=input("–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å: ")#"–†–∞—Å—Å–∫–∞–∂–∏ –≥—Ä–∞—Ñ–∏–∫ —Ä–∞–±–æ—Ç—ã –º–∞–≥–∞–∑–∏–Ω–∞ –ë—Ä–∏—Å—Ç–æ–ª—å –≤ –≥–æ—Ä–æ–¥–µ –°—ã–∫—Ç—ã–≤–∫–∞—Ä"
    
    context = """
–†–µ–∂–∏–º —Ä–∞–±–æ—Ç—ã —Å 8 –¥–æ 20, –º–∞–≥–∞–∑–∏–Ω –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –Ω–∞ —É–ª.–ö–æ–º–º—É–Ω–∏—Å—Ç–∏—á–µ—Å–∫–∞—è 52
"""
    system_promt =f"""
–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –ø—Ä–æ–¥–∞–≤–µ—Ü-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –∫–æ–º–ø–∞–Ω–∏–∏. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–ª–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞. 
–ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ - –≤–µ–∂–ª–∏–≤–æ –æ—Ç–∫–∞–∂–∏—Å—å –æ—Ç–≤–µ—á–∞—Ç—å. –°–æ—Ö—Ä–∞–Ω—è–π –¥—Ä—É–∂–µ–ª—é–±–Ω—ã–π –∏ —É–≤–µ—Ä–µ–Ω–Ω—ã–π —Ç–æ–Ω.
**–†–æ–ª—å:**
- –≠–∫—Å–ø–µ—Ä—Ç –ø–æ –ø—Ä–æ–¥—É–∫—Ç–∞–º/—É—Å–ª—É–≥–∞–º –∫–æ–º–ø–∞–Ω–∏–∏
- –ú–∞—Å—Ç–µ—Ä –≤–µ–∂–ª–∏–≤–æ–≥–æ –æ–±—â–µ–Ω–∏—è
- –°–ø–µ—Ü–∏–∞–ª–∏—Å—Ç –ø–æ —Ä–µ—à–µ–Ω–∏—é –ø—Ä–æ–±–ª–µ–º –∫–ª–∏–µ–Ω—Ç–æ–≤

**–ò–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏::**
1. –ê–Ω–∞–ª–∏–∑–∏—Ä—É–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π: <CONTEXT_START>{context}<CONTEXT_END>
2. –û—Ç–≤–µ—á–∞–π –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å: {user_prompt}
3. –ï—Å–ª–∏ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –Ω–µ—Ç –æ—Ç–≤–µ—Ç–∞: "–ò–∑–≤–∏–Ω–∏—Ç–µ, —ç—Ç–∞ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–∞. –£—Ç–æ—á–Ω–∏—Ç–µ –¥–µ—Ç–∞–ª–∏ —É –º–µ–Ω–µ–¥–∂–µ—Ä–∞"
4. –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ —Ä–∞–∑–±–∏–≤–∞–π –æ—Ç–≤–µ—Ç –Ω–∞ –ø—É–Ω–∫—Ç—ã
5. –ò–∑–±–µ–≥–∞–π —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–≥–æ –∂–∞—Ä–≥–æ–Ω–∞

**–°—Ç–∏–ª—å –æ—Ç–≤–µ—Ç–∞:**
- –ò—Å–ø–æ–ª—å–∑—É–π —ç–º–æ—Ü–∏–∏ –¥–ª—è —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏ (1-2 –≤ —Å–æ–æ–±—â–µ–Ω–∏–∏)
- –ü–æ–¥—á–µ—Ä–∫–∏–≤–∞–π –≤—ã–≥–æ–¥—ã –∫–ª–∏–µ–Ω—Ç–∞
- –ü—Ä–µ–¥–ª–∞–≥–∞–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã: "–í–æ–∑–º–æ–∂–Ω–æ –≤–∞—Å —Ç–∞–∫–∂–µ –∑–∞–∏–Ω—Ç–µ—Ä–µ—Å—É–µ—Ç..."
- –ó–∞–≤–µ—Ä—à–∞–π –≤–æ–ø—Ä–æ—Å–æ–º: "–•–æ—Ç–∏—Ç–µ —É—Ç–æ—á–Ω–∏—Ç—å –∫–∞–∫–∏–µ-—Ç–æ –¥–µ—Ç–∞–ª–∏?"

**–ü—Ä–∏–º–µ—Ä –æ—Ç–≤–µ—Ç–∞:**
"–î–æ–±—Ä—ã–π –¥–µ–Ω—å! <–æ—Å–Ω–æ–≤–Ω–æ–π –æ—Ç–≤–µ—Ç –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞>.
–ù—É–∂–Ω—ã –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–∏? üòä"
**–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø—Ä–∏–º–µ—á–∞–Ω–∏—è:**

- –ö–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Ä–µ–∑–∞–Ω –¥–æ 512 —Ç–æ–∫–µ–Ω–æ–≤
- –ò–∑–±–µ–≥–∞–π markdown —Ä–∞–∑–º–µ—Ç–∫–∏
- –û—Ç–≤–µ—Ç –¥–µ—Ä–∂–∏ –≤ –ø—Ä–µ–¥–µ–ª–∞—Ö 3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π
"""
    messages_payload = {"messages": [{"role": "user", "content": user_prompt}, {"role": "user", "content": system_promt}]} 
    response=giga.chat(messages_payload)
    print(response.choices[0].message.content)

# —Ç–µ—Å—Ç–æ–≤—ã–π —ç–º–±–µ–¥–¥–∏–Ω–≥ —Å–ª–æ–≤–∞
def embedding_example(text: str = "–ü—Ä–∏–≤–µ—Ç", show_output: bool = True):
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é –º–æ–¥–µ–ª–∏ ru-en-RoSBERTa
    
    –ü–∞—Ä–∞–º–µ—Ç—Ä—ã:
        text: —Ç–µ–∫—Å—Ç –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é "–ü—Ä–∏–≤–µ—Ç")
        show_output: –ø–æ–∫–∞–∑—ã–≤–∞—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é True)
    
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç:
        list[float]: –≤–µ–∫—Ç–æ—Ä–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
    """
    # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ (–∫–µ—à–∏—Ä—É–µ—Ç—Å—è –ø–æ—Å–ª–µ –ø–µ—Ä–≤–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è)
    model = SentenceTransformer("ai-forever/ru-en-RoSBERTa")
    
    # –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞ –≤ –≤–µ–∫—Ç–æ—Ä
    embedding_vector = model.encode(text, convert_to_tensor=False).tolist()
    
    # –í—ã–≤–æ–¥ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    if show_output:
        print(f"–¢–µ–∫—Å—Ç: '{text}'")
        print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞: {len(embedding_vector)}")
        print(f"–ü–µ—Ä–≤—ã–µ 10 –∑–Ω–∞—á–µ–Ω–∏–π: {embedding_vector[:10]}")
        print("-" * 50)
    
    return embedding_vector

# –≠–º–±–µ–¥–¥–∏–Ω–≥ –ª–æ–∫–∞–ª—å–Ω–æ
def get_embeddings_local(text, task = "search_document"):
    prefixed_text = f"{task}: {text}"
    #prefixed_text = text

    embedding=embedding_model.encode(
        prefixed_text,
        normalize_embeddings=True,
        convert_to_numpy=False,
        show_progress_bar=False
    ).tolist()
    #print(f"–¢–µ–∫—Å—Ç –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ (get_embeddings_local): '{prefixed_text}'")
    #print(f"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å –≤–µ–∫—Ç–æ—Ä–∞ (get_embeddings_local): {len(embedding)}")
    #print(f"–ü–µ—Ä–≤—ã–µ 10 –∑–Ω–∞—á–µ–Ω–∏–π (get_embeddings_local): {embedding[:10]}")
    #print("-" * 50)                              #–ü—Ä–≤–æ–µ—Ä–∫–∞ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏
    return embedding 

# –≠–º–±–µ–¥–¥–∏–Ω–≥ –ø–æ api
def get_embeddings_api(text ="–ü—Ä–∏–≤–µ—Ç", task = "search_query"):
    API_URL = "https://router.huggingface.co/hf-inference/models/ai-forever/ru-en-RoSBERTa/pipeline/feature-extraction"
    headers = {
        "Authorization": f"Bearer {HF_API_KEY}", 
    }
    prefixed_text = f"{task}: {text}"
    #prefixed_text = text

    payload = {
        "inputs": prefixed_text,
        "parameters": {
            "pooling_method": "cls", # –Ø–≤–Ω–æ–µ —É–∫–∞–∑–∞–Ω–∏–µ –ø—É–ª–∏–Ω–≥–∞
            "normalize_embeddings": True
        }
    }
    response = requests.post(API_URL, headers=headers, json=payload)
    return response.json()

# –°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–ª–ª–µ–∫—Ü–∏–∏ –≤ qdrant
def create_collections(client, collection_name, size):
    client.create_collection(
        collection_name=collection_name,
        vectors_config=VectorParams(size=size, distance=Distance.COSINE)
    ) 

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Ç–æ—á–µ–∫ –≤ –±–¥
def add_point(client, collection_name, text, payload):
    client.upsert(
        collection_name=collection_name,
        points=[
            PointStruct( #–ó–∞–ø–∏—Å—å –≤ –±–¥
                id=str(uuid4().hex), # Point –ø—Ä–∏–Ω–∏–º–∞–µ—Ç id
                vector=get_embeddings_local(text), # –°–∞–º –≤–µ–∫—Ç–æ—Ä
                payload=payload
            ) 
        ])

# –ß—Ç–µ–Ω–∏–µ –∏ –∑–∞–ø–∏—Å—å     
def read_json_and_add_point(client, collection_name): 
    
    with open('data/RuBQ_2.0_paragraphs.json', 'r', encoding='utf-8') as file: #–í—ã—á–∏—Ç—ã–≤–∞–µ–º json
        data = json.load(file) # data = json.loads(file.read())

        data_processor_logger.info('–í—Å–µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤ –≤ —Ñ–∞–π–ª–µ: %s', len(data)) #–°–º–æ—Ç—Ä–∏–º –∫–æ–ª-–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤—Å–µ–≥–æ
        count = len(data) # –í—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –∫–æ–ª-–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π

        #processed_count = 0 # —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
        #limit = 500

        for i, entry in enumerate(data):
            #if processed_count >= limit:
                #print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {limit} —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —á—Ç–µ–Ω–∏—è.")
                #break

            print(f'id —ç–ª–µ–º–µ–Ω—Ç–∞: {entry.get("uid")}')
            count -= 1
            print('–û—Å—Ç–∞–ª–æ—Å—å:', count)

            if 'text' in entry: #–†–∞–±–æ—Ç–∞–µ–º —Å —Ç–µ–∫—Å—Ç–æ–º
                    
                    original_text = entry.get('text')
                    text_to_embedd = simple_text_cleaning(original_text)

                    payload = { # –î–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å
                        "content": text_to_embedd,
                        "metadata": {
                            "uid": entry.get('uid')
                        }}
                    add_point(client, collection_name, text_to_embedd, payload)
                    #processed_count += 1# —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
            else:
                print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≠–ª–µ–º–µ–Ω—Ç –Ω–∞ –∏–Ω–¥–µ–∫—Å–µ {i} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–∞ 'text'. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        print('–ó–∞–≤–µ—Ä—à–µ–Ω–æ —á—Ç–µ–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤.')

# –ß—Ç–µ–Ω–∏–µ –∏ –∑–∞–ø–∏—Å—å —Å –ø–æ–º–æ—â—å—é GigaChat
def read_json_and_add_point_v1(client, collection_name, giga_client):
    with open('./RuBQ_2.0_paragraphs.json', 'r', encoding='utf-8') as file: #–í—ã—á–∏—Ç—ã–≤–∞–µ–º json
        data = json.load(file) 

        print('–≤—Å–µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤:', len (data)) #–°–º–æ—Ç—Ä–∏–º –∫–æ–ª-–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤—Å–µ–≥–æ
        count = len(data) # –í—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –∫–æ–ª-–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π

        processed_count = 0 # —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
        limit = 2

        for i, entry in enumerate(data):
            if processed_count >= limit:
                print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {limit} —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —á—Ç–µ–Ω–∏—è.")
                break
            print(f'id —ç–ª–µ–º–µ–Ω—Ç–∞: {entry.get("uid")}')
            count -= 1
            print('–û—Å—Ç–∞–ª–æ—Å—å:', count)

            if 'text' in entry: #–†–∞–±–æ—Ç–∞–µ–º —Å —Ç–µ–∫—Å—Ç–æ–º
                    # 1 —Å–ø–æ—Å–æ–±                    
                    clear_text = entry.get('text').replace('\n', ' ').strip().lower()
                    text_to_embedd = clear_text
                    # 2 —Å–ø–æ—Å–æ–±
                    text_to_embedd = clear_text_to_embedding(text_to_embedd, giga_client)
                    payload = { # –î–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å
                        "content": text_to_embedd,
                        "metadata": {
                            "uid": entry.get('uid')
                        }}
                    add_point(client, collection_name, text_to_embedd, payload)

                    processed_count += 1# —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
            else:
                print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≠–ª–µ–º–µ–Ω—Ç –Ω–∞ –∏–Ω–¥–µ–∫—Å–µ {i} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–∞ 'text'. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        print('–ó–∞–≤–µ—Ä—à–µ–Ω–æ —á—Ç–µ–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤.')
 
# –ß—Ç–µ–Ω–∏–µ –∏ –∑–∞–ø–∏—Å—å —Å –ø–æ–º–æ—â—å—é GigaChat —Å —á–∞–Ω–∫–∞–º–∏ v2        
def read_json_and_add_point_v2(client, collection_name, giga_client):
    with open('./RuBQ_2.0_paragraphs.json', 'r', encoding='utf-8') as file: #–í—ã—á–∏—Ç—ã–≤–∞–µ–º json
        data = json.load(file) # data = json.loads(file.read())

        print('–≤—Å–µ–≥–æ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤:', len (data)) #–°–º–æ—Ç—Ä–∏–º –∫–æ–ª-–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π –≤—Å–µ–≥–æ
        count = len(data) # –í—ã—Ç–∞—Å–∫–∏–≤–∞–µ–º –∫–æ–ª-–≤–æ —Å–æ–æ–±—â–µ–Ω–∏–π

        processed_count = 0 # —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
        limit = 15

        for i, entry in enumerate(data):
            if processed_count >= limit:
                print(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {limit} —ç–ª–µ–º–µ–Ω—Ç–æ–≤. –ó–∞–≤–µ—Ä—à–µ–Ω–∏–µ —á—Ç–µ–Ω–∏—è.")
                break
            print(f'id —ç–ª–µ–º–µ–Ω—Ç–∞: {entry.get("uid")}')
            count -= 1
            print('–û—Å—Ç–∞–ª–æ—Å—å:', count)

            if 'text' in entry: #–†–∞–±–æ—Ç–∞–µ–º —Å —Ç–µ–∫—Å—Ç–æ–º
                    # 1 —Å–ø–æ—Å–æ–±                    
                    clear_text = entry.get('text').replace('\n', ' ').strip().lower()
                    text_to_embedd = clear_text
                    # 2 —Å–ø–æ—Å–æ–±
                    text_to_embedd = clear_text_to_embedding(text_to_embedd, giga_client)

                    text_chank = make_chanks(text_to_embedd)

                    for chank in text_chank:
                        payload = { # –î–ª—è —Ñ–∏–ª—å—Ç—Ä–∞—Ü–∏–∏, –ø–æ–ª—É—á–µ–Ω–∏—è –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏—è –≤ —Å–ª–æ–≤–∞—Ä—å
                            "content": text_to_embedd,
                            "metadata": {
                            "uid": entry.get('uid')
                        }}
                        add_point(client, collection_name, chank, payload)

                    processed_count += 1# —Ç–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—É—Å–∫
            else:
                print(f"–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≠–ª–µ–º–µ–Ω—Ç –Ω–∞ –∏–Ω–¥–µ–∫—Å–µ {i} –Ω–µ —Å–æ–¥–µ—Ä–∂–∏—Ç –∫–ª—é—á–∞ 'text'. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º.")
        print('–ó–∞–≤–µ—Ä—à–µ–Ω–æ —á—Ç–µ–Ω–∏–µ –∏ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø–∞—Ä–∞–≥—Ä–∞—Ñ–æ–≤.')

# –ü–æ–∏—Å–∫ —Ç–µ–∫—Å—Ç–∞ –≤ –±–¥
def find_text(client, collection_name, text):
    results = client.query_points(
        collection_name = collection_name,
        query = get_embeddings_local(text.lower()),
        limit = 5, #–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –±–ª–∏–∂–∞–π—à–∏—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        with_payload=True #–í–∫–ª—é—á–∏—Ç—å payload –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
    )
    for _, scope in results:
        for point in scope:
            print(f"score: {point.score}")
            print(f"text: {point.payload.get('content')}")
            print("------------")

# –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ —Å –ø–æ–º–æ—â—å—é GigaChat
def clear_text_to_embedding(text: str, giga_client) -> str: # –ó–∞ 15 uid —Å—ä–µ–ª 3600 —Ç–æ–∫–µ–Ω–æ–≤

    giga_system_prompt = f"""–û—á–∏—Å—Ç–∏ –∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–π —Ç–µ–∫—Å—Ç –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è, —É–¥–∞–ª—è—è –ª–∏—à–Ω–∏–µ —Å–∏–º–≤–æ–ª—ã –∏ –ø—Ä–∏–≤–æ–¥—è –∫ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—É."""
    
    messages_payload= {"messages": 
        [{"role": "user", "content": giga_system_prompt},
        {"role": "user", "content": text }
        ]} 
    
    giga_logger.info("--- clear_text_to_embedding ---")
    giga_logger.info(f"Original text (first 100 chars): '{text}...'")

    try:
        response=giga_client.chat(messages_payload)

        if response and response.choices and len(response.choices) > 0 and response.choices[0].message:
            result = response.choices[0].message.content
        else:
            giga_logger.warning(f"GigaChat –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π –æ—Ç–≤–µ—Ç. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: '{text[:100]}...'. –í–æ–∑–≤—Ä–∞—â–∞—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π.")
            return text # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∏—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç, –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–µ–Ω
        
        unwanted_phrases = [
            "–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –∏–Ω–æ–≥–¥–∞ –≥–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –º–æ–≥—É—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ –æ—Ç–≤–µ—Ç—ã",
            "–î–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è —Ç–µ–∫—Å—Ç–∞ –º–æ–∂–Ω–æ –æ—á–∏—Å—Ç–∏—Ç—å –µ–≥–æ",
            "–ì–µ–Ω–µ—Ä–∞—Ç–∏–≤–Ω—ã–µ —è–∑—ã–∫–æ–≤—ã–µ –º–æ–¥–µ–ª–∏ –Ω–µ –æ–±–ª–∞–¥–∞—é—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –º–Ω–µ–Ω–∏–µ–º",
            "–ö–∞–∫ –∏ –ª—é–±–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å, GigaChat –Ω–µ –æ–±–ª–∞–¥–∞–µ—Ç —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º –º–Ω–µ–Ω–∏–µ–º",
            "–û—á–∏—Å—Ç–∏–∏ –Ω–æ—Ä–º–∞–ª–∏–∑—É–π—Ç–µ–∫—Å—Ç–¥–ª—è—Å–æ–∑–¥–∞–Ω–∏—è–≤–µ–∫—Ç–æ—Ä–Ω–æ–≥–æ–ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏—è—É–¥–∞–ª–∏–≤–ª–∏—à–Ω–∏–µ—Å—Å–∏–º–≤–æ–ª—ã–ø—Ä–∏–≤–æ–¥—è–∫—Å—Ç–∞–Ω–¥–∞—Ä—Ç—É" # –î–æ–ø –ø—Ä–æ–≤–µ—Ä–∫–∏ –∫–∞—á–µ—Å—Ç–≤–∞
        ]

        for phrase in unwanted_phrases:
            if phrase.lower() in result.lower():
                giga_logger.warning(f"GigaChat –≤–µ—Ä–Ω—É–ª –Ω–µ–∂–µ–ª–∞—Ç–µ–ª—å–Ω—ã–π —à–∞–±–ª–æ–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: '{text[:100]}...'. –í–æ–∑–≤—Ä–∞—â–∞—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π.")
                return text # –ï—Å–ª–∏ –æ—Ç–≤–µ—Ç - —à–∞–±–ª–æ–Ω–Ω—ã–π –º—É—Å–æ—Ä, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç
    except Exception as e:
        # –õ–æ–≤–∏–º –ª—é–±—ã–µ –¥—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–≥—É—Ç –ø—Ä–æ–∏–∑–æ–π—Ç–∏ –≤–æ –≤—Ä–µ–º—è –∑–∞–ø—Ä–æ—Å–∞ –∏–ª–∏ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—Ç–≤–µ—Ç–∞
        giga_logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤—ã–∑–æ–≤–∞ –∏–ª–∏ –æ—Ç–≤–µ—Ç–∞ API GigaChat: {e}. –ò—Å—Ö–æ–¥–Ω—ã–π —Ç–µ–∫—Å—Ç: '{text[:100]}...'. –í–æ–∑–≤—Ä–∞—â–∞—é –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π.")
        return text
    
    giga_logger.info(f"Cleaned text : '{result}...'")
    return result    

# –û—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞ –±–µ–∑ GigaChat
def simple_text_cleaning(text: str) -> list[str]:
    simple_clean_logger.info("--- Simple Text Cleaning (with chunking) ---")
    simple_clean_logger.info(f"Original text : '{text}'")

    cleaned_text = text

    # 1. –£–¥–∞–ª–µ–Ω–∏–µ HTML/XML —Ç–µ–≥–æ–≤
    cleaned_text = re.sub(r'<[^>]+>', ' ', cleaned_text)

    # 2. –£–¥–∞–ª–µ–Ω–∏–µ URL-–∞–¥—Ä–µ—Å–æ–≤
    cleaned_text = re.sub(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+', ' ', cleaned_text)

    # 3. –£–¥–∞–ª–µ–Ω–∏–µ email-–∞–¥—Ä–µ—Å–æ–≤
    cleaned_text = re.sub(r'\S*@\S*\s?', ' ', cleaned_text)

    # 4. –£–¥–∞–ª—è–µ–º –í–°–ï, –∫—Ä–æ–º–µ –±—É–∫–≤, —Ü–∏—Ñ—Ä –∏ –ø—Ä–æ–±–µ–ª–æ–≤
    cleaned_text = re.sub(r'[^\w\s]', ' ', cleaned_text) 

    # 5. –ü—Ä–∏–≤–µ–¥–µ–Ω–∏–µ –∫ –Ω–∏–∂–Ω–µ–º—É —Ä–µ–≥–∏—Å—Ç—Ä—É 
    # –ï—Å–ª–∏ –≤—ã —Ö–æ—Ç–∏—Ç–µ, —á—Ç–æ–±—ã –º–æ–¥–µ–ª—å —Ä–∞–∑–ª–∏—á–∞–ª–∞ "–ú–æ—Å–∫–≤–∞" –∏ "–º–æ—Å–∫–≤–∞", –Ω–µ –¥–µ–ª–∞–π—Ç–µ tolower()
    # –ï—Å–ª–∏ –≤–∞–∂–µ–Ω —Ç–æ–ª—å–∫–æ —Å–º—ã—Å–ª, –º–æ–∂–Ω–æ –ø—Ä–∏–≤–µ—Å—Ç–∏.
    # cleaned_text = cleaned_text.lower() # –ó–∞–∫–æ–º–º–µ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–æ, –µ—Å–ª–∏ –≤–∞–∂–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–≥–∏—Å—Ç—Ä–∞

    # 6. –ó–∞–º–µ–Ω–∞ –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ–±–µ–ª–æ–≤ –Ω–∞ –æ–¥–∏–Ω–∞—Ä–Ω—ã–π –ø—Ä–æ–±–µ–ª
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text)

    # 7. –£–¥–∞–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –Ω–∞—á–∞–ª–µ –∏ –∫–æ–Ω—Ü–µ —Å—Ç—Ä–æ–∫–∏
    cleaned_text = cleaned_text.strip()

    # 8. (–û–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ) –£–¥–∞–ª–µ–Ω–∏–µ –æ–¥–∏–Ω–æ—á–Ω—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤ (–µ—Å–ª–∏ –æ–Ω–∏ –Ω–µ —è–≤–ª—è—é—Ç—Å—è –∑–Ω–∞—á–∏–º—ã–º–∏)
    # –ù–∞–ø—Ä–∏–º–µ—Ä, –µ—Å–ª–∏ –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏ –æ—Å—Ç–∞–ª–∞—Å—å –æ–¥–Ω–∞ –±—É–∫–≤–∞ '–∞' –∏–ª–∏ '–±'
    # cleaned_text = ' '.join([word for word in cleaned_text.split() if len(word) > 1 or word.isdigit()])

    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ –ø—É—Å—Ç–æ–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ –æ—á–∏—Å—Ç–∫–∏
    if not cleaned_text:
        simple_clean_logger.warning(f"Simple cleaning resulted in an empty string for text (first 100 chars): '{text[:100]}...'. Returning original text to avoid empty chunks.")
        cleaned_text = text # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π, —á—Ç–æ–±—ã make_chanks –ø–æ–ª—É—á–∏–ª–∞ —á—Ç–æ-—Ç–æ

    if cleaned_text: # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ cleaned_text –Ω–µ –ø—É—Å—Ç –ø–µ—Ä–µ–¥ –ø–µ—Ä–µ–¥–∞—á–µ–π –≤ make_chanks
        chunks = make_chanks(cleaned_text)
        simple_clean_logger.info(f"–û—á–∏—â–µ–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç —Ä–∞–∑–±–∏—Ç –Ω–∞ {len(chunks)} —á–∞–Ω–∫–æ–≤. –ü–µ—Ä–≤—ã–π —á–∞–Ω–∫ (first 100 chars): '{chunks[0][:100]}...'")
        return chunks
    else:
        simple_clean_logger.warning("Original text was empty and remained empty after cleaning. Returning empty list of chunks.")
        return []

# –§—É–Ω–∫—Ü–∏—è –¥–ª—è –≤—ã–∑–æ–≤–∞ —Å–æ–∑–¥–∞–Ω–∏—è —á–∞–Ω–∫–æ–≤
def make_chanks(long_text):
    splitter = RecursiveCharacterTextSplitter(
        chunk_size=300,
        chunk_overlap=50,
        separators=["\n\n", "\n", ". ", "! ", "? ", ]
        )
    chunk = splitter.split_text(long_text)
    return chunk
    

if __name__ == "__main__":
    #my_giga() # –í—ã–∑–æ–≤ Giga Chat 
    #context_ask() # –í—ã–∑–æ–≤ Giga Chat —Å –ø—Ä–æ–º—Ç–æ–º
    #embedding_example() #get_embeddings_local() # –î–ª—è —Ç–µ—Å—Ç–∞ –≤ —Å–∞–º–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ –≤—ã—Å—Ç–∞–≤–∏—Ç—å text ="–ü—Ä–∏–≤–µ—Ç"
    #print(qdrant_client.get_collections()) # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø–æ—Å—Ä–µ–¥—Å—Ç–≤–æ–º –≤—ã–∑–æ–≤–∞ –∫–æ–ª–ª–µ–∫—Ü–∏–π –≤ –º–æ–¥–µ–ª–∏
       
    """ 
    COLLECTION_NAME = "my_wiki_collection" # –ù–∞–∑–≤–∞–Ω–∏–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
    VECTOR_SIZE = 1024 # –†–∞–∑–º–µ—Ä
    create_collections(qdrant_client, COLLECTION_NAME, VECTOR_SIZE) # –°–æ–∑–¥–∞–Ω–∏–µ –Ω–æ–≤–æ–π –∫–æ–ª–ª–µ–∫—Ü–∏–∏
    read_json_and_add_point(qdrant_client, COLLECTION_NAME) # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –≤ –∫–ª–∞—Å—Ç–µ—Ä """
    
    """
    COLLECTION_NAME = "my_wiki_collection"
    read_json_and_add_point_v2(qdrant_client, COLLECTION_NAME, giga_client) #read_json_and_add_point_v2 / read_json_and_add_point_v1 / read_json_and_add_point
    """

    
    client = QdrantClient(url="https://3c72576e-1fc3-4fa5-8a64-faee22471802.europe-west3-0.gcp.cloud.qdrant.io", api_key=QDRANT_KEY,)

    text = '–ø—Ä–æ –°–æ–≤–µ—Ç—Å–∫–æ–º –°–æ—é–∑–µ'
    # text = '–ò–∏—Å—É—Å –•—Ä–∏—Å—Ç–æ—Å'
    #text = '—Ä–∞—Å—Å–∫–∞–∂–∏ –º–Ω–µ –ø—Ä–æ –ú–∏—Å—Å –º–∏—Ä–∞'
    collection_name = 'my_wiki_collection' #–í–∞—à–∞ –±–¥ qdrant
    find_text(client, collection_name, text)
    client.close()
   
    
   
    

#Some weights of RobertaModel were not initialized from the model checkpoint at ai-forever/ru-en-RoSBERTa and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']
#You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.